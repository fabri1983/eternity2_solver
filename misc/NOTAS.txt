
---------------------------------------------------------------------------------------
TODO
----
- Guardar pos_multi_process_offset en archivo status. Y setearlo cuando se carga status.
- Guardar num_processes_orig[] en archivo status. Y setearlo cuando se carga status. 
---------------------------------------------------------------------------------------

---------------------------------------------------------------------------------------
Código comentado:
-----------------
- se comentó el uso de desde_saved[] porque ahora se calcula cuando se guarda estado.
- se comentó todo el uso de retroceder y cursor <= cursor_invalido (@RETROCEDER).
- se comentó el uso de poda contorno inferior en SolverFaster.java y Contorno.java (@CONTORNO_INFERIOR).
---------------------------------------------------------------------------------------

---------------------------------------------------------------------------------------
Timings
-------
- Environment: Windows 10 Home, Intel Core i7-2630QM (2.9 GHz max per core), DDR3 666MHz. OpenkJDK 1.8.0_242-b06. Results:
5 >>> 1898 ms, cursor 211
7 >>> 4490 ms, cursor 211

This numbers helps to easily check if some change has improved on worsen the performance.
However, the key number to keep an eye is the number of correct tiles per second. 
	For that benchmarking use: -Dui.show=false -Dmax.ciclos.save.status=false -Dmax.ciclos.print.stats=147483647
---------------------------------------------------------------------------------------

---------------------------------------------------------------------------------------
Java GC
https://plumbr.io/handbook/what-is-garbage-collection
---------------------------------------------------------------------------------------

---------------------------------------------------------------------------------------
Fork/Join approach
------------------
Uso de un ForkJoinPool executor que ejecuta instancias de RecursiveAction (RecursiveAction no retorna valor).
ExplorationTask por el momento no usa fork, por lo que siempre existirá una cantidad fija de actions.
Esta decisión es porque cada action creada va a ejecutar una rama del arbol de exploracion a partir de cierta posición.
Aqui la lógica es la misma que la usada en SolverMPJE.
Asique la logica de qué rama atacar es inherente al solver cuando se usa un approach de procesamiento paralelo.
Se decide a partir de una posición seteada por configuración.

Fork/Join:
Me parece q viene de la mano de async forks.
	consider using a pool constructed in asyncMode.
	ForkJoinTask: typically RecursiveAction for most computations that do not return results, RecursiveTask for those 
		that do, and CountedCompleter for those in which completed actions trigger other actions.
	CountedCompleters may be better choices when applying a possibly time-consuming operation (that cannot be further 
		subdivided) to each element of an array or collection. Especially when the operation takes a significantly different 
		amount of time to complete for some elements than others. So there is no need other threads to block waiting for it.

Para cuando se debe aplicar una operación a un arreglo independientemente de cada elemento se puede utilizar CountedCompleters.
Ver en http://gee.cs.oswego.edu/dl/jsr166/dist/docs/java/util/concurrent/CountedCompleter.html
---------------------------------------------------------------------------------------

---------------------------------------------------------------------------------------
Optimizaciones:
---------------
- Lot of Bitwise tricks
https://medium.com/@shashankmohabia/bitwise-operators-facts-and-hacks-903ca516f28c
https://graphics.stanford.edu/~seander/bithacks.html
https://www.hackerearth.com/practice/notes/bit-manipulation/

- Modulo operation X % Y.
The clever optimization is to use the bitwise AND operation which eliminates the use of loops and is a very fast CPU operation.
It requires that your modulo divisor is a power of 2 and dividend is positive, but if your code can support this then here is the method:

	public final static int fastModulo(int dividend, int divisor)
	{
	   return dividend & (divisor - 1);
	}

Another modulo reduction to bitwise operations:
http://homepage.cs.uiowa.edu/~jones/bcd/mod.shtml

Fast alternative to modulo reduction:
	https://lemire.me/blog/2016/06/27/a-fast-alternative-to-the-modulo-reduction/

	(IT DIDN'T WORK IN MY ALGORITHM)
	public static int reduce(int dividend, int divisor) {
        return (int) (((dividend & 0xffffffffL) * divisor) >>> 32);
    }

New Reduction method:
	https://www.nayuki.io/page/barrett-reduction-algorithm

- Usar java.nio buffers puede agilizar el acceso. No sé a partir de que version de JVM.
We need to use direct NIO buffers instead of arrays, but HotSpot can access direct NIO buffers as fast as arrays (http://blog.vlad1.com/2011/10/05/looking-at-java-nio-buffer-performance/).
De donde saqué la idea: http://stackoverflow.com/questions/10784951/do-any-jvms-jit-compilers-generate-code-that-uses-vectorized-floating-point-ins
Example: http://www.java-gaming.org/index.php?PHPSESSID=2ftumjcjo00el2q4vs28louqj5&topic=12346.msg98913#msg98913

- no usar volatile para estructuras que se acceden por varios threads. Volatile fuerza que todos los 
threads siempre vean la última modificación de la variable, lo que significa una especie de sincronización implícita.

- Cambiar las comparaciones y comparación/asignación de numeros por operadores de bit.
Ej:
	if (x == a) x= b;
  	else x= a;

	x= a ^ b ^ x; //where x is equal to either a or b

- Cada vez que se crea un arreglo este se inicializa en tiempo de ejecución. Entonces cada vez
que se invoca un metodo que crea un arreglo local se está perdiendo tiempo en incializacion. 
Lo mejor es crearlo como static.

- Usar variables int en vez de short o byte. Java está optimizado para int.
Care when using byte, short and char: When stored in a variable, built in types like byte, short, 
char and boolean all are represented as 32 bit values just like int and also use the same bytecode 
for loading and storing. The differerence in the memory used comes only when these built in types 
are stored in arrays. When stored in arrays, boolean and byte values are stored as 8-bit values, 
while short and char values are stored as 16-bit values.
Note that int, float, and object reference values are always stored as 32-bits each, and long and 
double values are always stored as 64-bit values.
The fastest types of variables are int and reference variables. This is because all operations on 
byte, short, and char are performed as ints, and assigning the results to a variable of the 
corresponding type requires an explicit cast.

- Usar menos llamadas de funciones porque provocan overhead de invocación.

- Strength reduction
Strength reduction occurs when an operation is replaced by an equivalent operation that executes faster. 
The most common example of strength reduction is using the shift operator to multiply and divide 
integers by a power of 2. For example, x >> 2 can be used in place of x / 4, and x << 1 replaces x * 2. 

- The first rule is to use a local int variable for the loop counter: for (int i=0;...).

- Rather than comparing i against N at each iteration, which requires N to be loaded 
(assuming N isn't a constant or static final variable), restructure the loop to take advantage 
of the efficient checks against 0. Comparing against zero is almost always more efficient in any 
language since the underlying tests are based on < 0, <= 0, == 0, != 0, >= 0 and > 0. 
To optimize, restructure the loop as:
	for (i = N; --i >= 0; ) {
	    // do something
	}
---------------------------------------------------------------------------------------

---------------------------------------------------------------------------------------
Tips && Notes
-------------

- Usar enum para los flags. Es mas rápido para procesar los switch-case.
Link: http://stackoverflow.com/questions/4922932/java-performance-of-enums-vs-if-then-else 

- Acotar pila de llamadas: una vez que paso cierta posición (por ejemplo la 70) puedo hacer lo mismo
que cuando se carga estado para no tener en la pila 70 frames que sé no voy a modificar en mucho tiempo.

- Cuántas combinaciones voy realizando teniendo en cuenta todo el arbol de exploración?
En cada posición cuando obtengo la lista de posibles piezas desde super_matriz[] estoy acotando las posibles ramas 
por las que me puedo ir. 
Cuando podo en la posición cursor estoy descartando: 
	corner_libres! * edges_libres! * (inner_libres - hints)! * 4^(inner_libres - hints)

- Cantidad de nodos visitados:
Un nodo es una ubicación del arbol de exploración. En cada nodo puedo elegir varias piezas.
Entonces es contabilizar las piezas que voy probando.
Lo siguiente es extracto del yahoo group:

	If you download eternityIIJavaV0.8.zip from the file area (doc_smith
	folder) and check SimpleSearch.java method solve() you may get an idea.
	
	_numNodes++;
	counts the overall nodes
	
	_counts[depth]++;
	counts the nodes at each individual search depth.

- Limites de números: 
El entero mas grande de 31 bits es 2147483648. Usar 2147483647 en Complemento a 2.
El entero mas grande de 63 bits es 9223372036854775808. Usar 9223372036854775807 en Complemento a 2.

- Analizando los sizes de las diferentes matrices en MultiDimensionalStrategy:
  * existen como máximo 6 piezas interiores (repitiéndose si tiene mas de una rotación) para combinación de hasta 3 colores consecutivos. 
  * existen 4 piezas para borde/esquina.

Sabiendo que existen las siguientes celdas y rotaciones:
 - 4 celdas esquinas: 4! * 4^0 (no se rota una vez ya colocada, por eso vá ^0)
 - 56 celdas de borde: 56! * 56^0 (no se rota una vez ya colocada, por eso vá ^0)
	Pero cada pieza borde puede matchear con hasta otras 12 piezas de borde debido a sus 5 colores que solo pertenecen a borde.
	Por lo que sería: 12!^5
	Pero como mencioné arriba solo voy a matchear con hasta 4 piezas como máximo.
	Por lo que sería: 4!^5
 - 195 celdas internas: 195! * 4^195 (4 rotaciones por cada una de ellas)
	Pero cada pieza interior puede matchear con hasta otras 25 piezas de interior debido a sus 17 colores que solo pertenecen a borde.
	Por lo que sería: (25!^17) * (4^25)
	Pero como mencioné arriba solo voy a matchear con hasta 6 piezas como máximo (incluyendo rotadas) y asi eliminando las rotaciones.
	Por lo que sería: 6!^17
 - 1 celda interna fija (son 5 hints pero en mi solver solo tengo 1)

El calculo sin los calculos que logré:
	(4! * 4^0) * (12!^5) * (25!^17) * (4^25) = 1.1867859208314115028159356514226040602607695162035434... × 10^488

El cálculo con las matrices multidimensionales que uso en el solver:
	(4! * 4^0) * (4!^5) * (6!^17) = 7.176619 × 10^56
	
El uso de contorno_sup en el interior del tablero hace que una combinación dada left-top-top se pueda usar una 
sola vez lo que hace descartar ramas. Pero no sé cómo hacer ese cálculo.

Si promediamos a 50% (2) intentos de pieza borde, y 50% (3) intentos de pieza interna nos queda:
	(4! * 4^0) * (2!^5) * (3!^17) = 1.2999... × 10^16
---------------------------------------------------------------------------------------

---------------------------------------------------------------------------------------
MPI
---

- Cuando inicio por primera vez se hace la sincronización solo a fines de poder largar todos los procesos 
a la vez. Si se carga estado no se debe sincronizar pues cada proceso ya sabe qué parte del arbol tomar.
Esto me brinda poder salvar N archivos de estado para luego dispersarlos y continuar la exploracion 
sin tener que esperar que los procesos dispersos se sincronicen.

- Funcionamiento de la sincronización:

  - Antes de llamar a exploracionStandard():

	if ((cursor == POSICION_MULTI_PROCESSES) && (sincronizar))
		sincronizar = false; //sincronizo una sola vez
		if (rank == 0)
			Send() a todos los procesos y esperar a que todos los recivan
		else
			Receive() sincrónico para que esperen el mensaje de rank(0)
		Esta logica esta implementada en metodo knocKnock()
  - Dentro de exploracionStandard():

	if (cursor == POSICION_MULTI_PROCESSES)
		establezco los limites del for. Aqui iría la lógica de asignación de ramas en uno o mas niveles
		del arbol de exploración. 

- Cómo comunico a los demás procesos que se encontró solución y mandarla para que todos se detengan? 
Desafortunadamente hacer llamadas Send y Receive dentro de un loop ocasionaría unexpected messages y si 
existen otras llamadas Send y Receive estas se cancelarian o se mezclarían con las anteriores.

- Qué hacer si un proceso no encontró solución?
Esto es importantísimo porque está diciendo "no voy mas por esta rama porque conduce a nada". 
Tambien usar un thread que llame a MPI.Recv con ANY_SOURCE y TAG_NO_SOLUTION. 
Las ramas que ya no sirvan mas se pueden ir guardando en el archivo de estado al final y tener un 
procesamiento especial que evitara explorar dichas ramas. El problema es cómo almaceno una rama para 
luego saber que por ella no tengo que ir (lista de desde_saved?) 
---------------------------------------------------------------------------------------

---------------------------------------------------------------------------------------
Filas precalculadas:
--------------------
- No se utiliza más el arreglo de rotaciones en "posibles" por lo tanto hay que cambiar las comparaciones en FilaPiezas.

- El uso de pos_carga (cuando se calcula) genera un problema: es necesario setear como no usadas
las piezas en las posiciones de tablero que voy a usar, antes de colocar pieza alguna. Esto genera
un overhead. Sin dicha operación podría setear como no usada una pieza que ya suponía usada (colocada
en posiciones anteriores).

- Para lo de copiado de filas usando sun.misc.Unsafe
Cuando se calculen todas las posibles combinaciones de filas ir guardándolas en memoria contigua usando allocateDirect. 
Tal vez no sea necesario si ya se guardan contiguamente.
Luego cuando necesitemos copiar una fila al tablero hacerlo con copyDirect. 
NOTA: usar sun.misc.Unsafe siempre y cuando no tenga esos datos en Java Heap porque sino me parece que se copian desde Off Heap.

Usar todos los accesos a arreglos de tipo nativo con getAdress. 
Supuestamente acceder directamente a la memoria nativa y no al heap debería ser más rápido.

- Filas precalculadas:
para 2 columns tengo count maximo 29   con      34926 filas calculadas.
para 3 columns tengo count maximo 91   con    1556132 filas calculadas.
para 4 columns tengo count maximo 297  con   68981072 filas calculadas.
para 5 columns tengo count maximo ??   con 3042060164 filas calculadas.
---------------------------------------------------------------------------------------

---------------------------------------------------------------------------------------
Contorno de piezas
------------------
- Idea:
Cada pieza ahora tiene su idUnico. Por lo tanto para un contorno de 2 columnas (left-top-top) dado existe un 
conjunto de tripletas de piezas irrepetibles según su idUnico. 
Ejemplo: para contorno 12-7-8 existen las tripletas (123,78,167), (99,101,452), etc. Estas tripletas apuntan al mismo contorno.
Ahora preguntar si un contorno está usado es preguntarle a la referencia en cuestión.
No sé si sería mas rápido que lo actualmente implementado. Peeeeero... las tripletas que apuntan a ese contorno 
no pueden ser cargadas en tablero. Por lo que puedo tener un objeto PunteroContorno el cual contiene las 
tripletas a ese contorno. Si el puntero es usado entonces puedo evitar que se formen esas tripletas en tablero 
(muy costoso con el modelo de pieza unica actual).   

- Notas:
	* Usando solamente restricción de contorno superior con 2 cols tardo 34.5 segs hasta la pos 211, cuando el 
	backtracker común tarda 99 segs (mismo resultado en ambos casos!!).
	Pero para la posición 209 tardaba 89 segs contra 43 segs del backtracker simple y no son los mismos resultados,
	por lo tanto usando contorno superior existe realmente una disminución del árbol de exploración.
	Esto se deduce por el ordenamiento de las piezas y su acceso también ordenado.
	
	* Usar mas de 2 columnas solamente me hace perder tiempo ya que alcanzo pos 211 con mismo resultado pero en 
	mayor tiempo. Me parece que esto es un hecho notable. Si con diferentes algoritmos llego a una misma posición 
	por vez primera con mismo resultado todas ellas, entonces la de menor tiempo es la que logró optimizar el recorrido.
	
	* Verificar: usar solamente contorno superior porque el uso de inferior ralentiza el backtracking y el 
	"benificio" del uso de contorno inferior es superado por la velocidad del backtracker. (HASTA AHORA 
	PARECE CIERTO, pero debería tomar los tiempos en que tarda con y sin contorno inf hasta una posición lejana).
	 
- Así tiene que ser:
	* Detectar los contornos superiores e inferiores en tablero de las piezas usadas.
	* Setear contorno usado se hace de dos maneras: superior e inferior. El superior se setea desde la fila 1
	(0-based) hasta la fila 14 (inclusive). El inferior se setea desde la fila 2 hasta fila 14 (inclusive).
	* La poda es preguntar si las celdas vacias que tengo que llenar tienen que formar un contorno ya usado.
	Entonces en explorar() cuando estoy en posición adecuada pregunto si no existe contorno	superior usado.
	* Una vez que seleccioné pieza y la coloqué en tablero[] pregunto si estoy en posición adecuada y me 
	fijo si el contorno inferior que generé no está usado.
---------------------------------------------------------------------------------------

---------------------------------------------------------------------------------------
Colors
------
According misc/colors_mapping_original.jpg
Grey: 0
Corner and border only colors:  1,  5,  9, 13, 17
Inner colors: 2, 3, 4, 6, 7, 8, 10, 11, 12, 14, 15, 16, 18, 19, 20, 21, 22

THIS IS THE CURRENT MAPPING:
According misc/colors_mapping_rearranged.jpg
Grey: 22
Corner and border only colors: 17, 18, 19, 20, 21
Inner colors: 0, 1, 2, 3, 4, 5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16
---------------------------------------------------------------------------------------

---------------------------------------------------------------------------------------
Supuestas piezas fijas:
----------------------
Las filas y columnas NO están en 0-based. La rotación es 0-based.

(num)	(fila)	(col)	(rotacion)	(rot original del chabón) 
208		3		3		1			(3)
181		14		3		1			(3)
139		9		8		0			(2)
255		3		14		1			(3)
249		14		14		2			(0)
---------------------------------------------------------------------------------------
